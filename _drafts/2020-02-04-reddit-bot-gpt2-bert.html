---
layout: post
title: How to build a pretty convincing reddit personality with GPT2 and BERT
date: '2019-02-04'
author: Will Stedden
tags: 
- data science
- artificial intelligence
---

<p>
	Last month, I experimented with building a . I wrote another post on the background, but here I wanted to 
</p>

<h5>Fine tuning GPT-2 and generating text for reddit</h5>
<p>
	If you were to use GPT-2 straight "out-of-the-box," you'd end up generating text that could look like anything you might find on the internet.  Sometimes it'll generate a news article, sometimes it'll generate a cooking blog recipe, sometimes it'll generate a rage-filled facebook post.  You don't really have too much control, and therefore, you won't really be able to use it to effectively generate reddit comments.
</p>
<p>
	To overcome this issue, I needed to "fine-tune" the pretrained .  Fine-tuning means taking a trained model, and then continung to train it only on the exact type of data.  This process (somewhat magically) allows you to take a lot of the general information about language from the big pretrained model, and sculpt that down with all the specific information about the exact output format you are trying to generate.
</p>

<p>
	Fine-tuning is a standard process, but it still isn't super easy to do.  I'm not an expert deep learning researcher, but fortunately for me, some really wonderful experts have built some incredibly simple wrapper utilities for performing this task with the GPT-2 model.  I used gpt-simple 
</p>


<p>
	The best part is that the author of gpt2-simple even set up a Google Colaboratory notebook that .  Google Colaboratory is an amazing FREE resource that lets you run a python jupyter notebook on a Google GPU server.  As a warning, I am officially a lifetime fanboy of Google for making a free tier on Google App Engine, BigQuery, and Google Colab*. 
</p>

<p>
	You can follow along with this tutorial notebook to learn all about how to fine-tune a GPT-2 model with gpt2-simple.  I took all of that code and condensed and reformatted it a little to make this gpt-2 fine tuning notebook.  
</p>

<p>
	The data I used to fine-tune the model came from reddit comments.  There is an ongoing project that scrapes reddit post and comments and stores them in a bunch of Google BigQuery tables.  To me, it's very surprising that I couldn't find more information about this project, but I used a few stackoverflow and reddit comments to piece together the format of the queries I'd need
</p>

<p>
	I've stored the . I used the bigquery python API to automate the generation of the queries I needed to download the data across a number of months in 2017 and 2018.  Because I wanted to be able to prime the algorithm with a comment and generate a reply, I reformatted the data to look like the following.
</p>

<pre>
	"a bunch of primary comment text" [SEP] "all of the reply text"
</pre>

<p>
	When I train the model with this format, I can then feed the trained model a string like <code>"some new primary comment text" [SEP]</code>, and it will generate <code>"some new reply"</code>. The gpt-2 simple tutorial explains in detail how to feed this kind of data into the fine-tuning script.  You can check out my script here too, to see how I did it, but I don't have a lot of comments in there yet.
</p>

<p>
	As I mentioned above, the output of this model, while normally somewhat reasonable, is still a far cry from 
</p>


<h4>Training BERT models for fake detection and upvote prediction</h4>

<p>
	To improve the quality of responses, I create a whole bunch of candidate responses using the GPT2 generator above, and then I use another model to filter out which are the best replies I could release.  To determine the best, I actually want to do two things:
</p>

<ul>
	<li>Filter out unrealistic replies</li>
	<li>For the realilstic replies, pick the one that I predict will have the most upvotes</li>
</ul>

<p>
	
</p>

<p>
	Again, I'm not the biggest expert in working with deep learning infrastructure so luckily, another brilliant soul wrote a tutorial for fine-tuning text classifier models using a pretrained BERT network.  And not only that, by some miracle, they wrote their tutorial in a Google Colab notebook too!  So all I had to do was combine the two.
</p>

<p>
	In an ideal world, I would have combined the two scripts into one that could be run from end to end.  Unfortunately, a quirk in the way the designers immplemented the gpt2-simple package made it impossible to have to computation graphs instantiated in the same environment.  Instead, I just stored the intermediate artifacts in csv files on my google drive.  So the protocol is to run the GPT2 generator notebook to generate a batch of candidate replies, and then run the BERT discriminator models to 
</p>

<h4>Automating comments with PRAW</h4>



<h4>Ethicality of impersonating humans</h4>

Getting into the brass tacks of how to finetune/modify gpt2 and bert.  and how to combine them together with the reddit bot.  

step 0: get some reddit comment data from your favorite subreddits and filter out [deleted] and [removed] text  

step 1: fine tune GPT-2 on reddit "comment [SEP] reply" text https://minimaxir.com/2019/09/howto-gpt2/  

step 2a: fine tune BERT to differentiate real replies from fake ones step 
2b: fine tune BERT to predict how well real comments perform  

step 3: use praw to download current comments  

step 4: use fine-tuned GPT2 to generate 10 replies to some comments  

step 5: pass the generated replies to both of the BERT models to generate a prediction of realness and score  

step 6: use some criteria for selecting which replies to try  

step 7: use praw to submit the comments



<p><small>
	* I know someday they will take over and destroy the world, but I still think they (along with Github) have done more good just by making these functions freely available for young tinkerers to explore.
</small></p>
